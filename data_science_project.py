# -*- coding: utf-8 -*-
"""Data_Science_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16-L44VAoQk7iB50WR8mv1UA_oidOn5Ug
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import ttest_ind
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

column_names = ["Subject identifier", "Jitter", "Jitter Absolute", "Jitter Relative", "Jitter 5-point",
                "Jitter DDP", "Shimmer", "Shimmer Absolute", "Shimmer 3-point", "Shimmer 5-point",
                "Shimmer 11-point", "Shimmer DDA", "Harmonicity Autocorrelation", "Harmonicity NHR",
                "Harmonicity HNR", "Pitch Median", "Pitch Mean", "Pitch Std", "Pitch Min", "Pitch Max",
                "Pulse Num", "Pulse Periods", "Pulse Mean Period", "Pulse Std Period", "Voice Fraction Unvoiced",
                "Voice Num Voice Breaks", "Voice Degree Voice Breaks", "UPDRS", "PD indicator"]

df = pd.read_csv("/content/po1_data.txt", names=column_names, skiprows=1) #loading the data set
#df.head(10)                               #printing the first 10 rows of dataframe

df.shape

df.info()

dfnew = df.copy()
dfnew.head(10)

feature_columns = dfnew.columns[1:-1]  # Excluding Subject ID and PD indicator
pd_indicator_column =dfnew.iloc[:,-1:] #"PD indicator"

pd_indicator_column
#pd_indicator_column.astype('bool')

feature_columns

print(dfnew[feature_columns].describe()) #exploring the data

num_features = len(feature_columns)
num_rows = (num_features + 1) // 2  # Number of rows for subplots for boxplot

plt.figure(figsize=(15, 5 * num_rows))

for index, feature in enumerate(feature_columns, 1):
    plt.subplot(num_rows, 2, index)
    sns.boxplot(data=dfnew, x='PD indicator', y=feature)
    plt.title(f"Box Plot of {feature} by PD Indicator")

plt.tight_layout()
plt.show()

correlation_df = dfnew.corr()[['PD indicator']].sort_values(by='PD indicator', ascending=False)

# Print correlation for every feature
print(correlation_df)

correlation_matrix = dfnew.corr()

# correlation heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, cmap="coolwarm", annot=True, fmt=".2f", linewidths=0.5)
plt.title("Correlation Heatmap")
plt.show()

# t-test and other statical tests on the dataframe
ppd_data = dfnew[dfnew['PD indicator'] == 1]
non_ppd_data = dfnew[dfnew['PD indicator'] == 0]

for feature in feature_columns:
    t_stat, p_value = ttest_ind(ppd_data[feature], non_ppd_data[feature])
    print(f"Feature: {feature}\tT-Stat: {t_stat:.2f}\tP-Value: {p_value:.4f}")

# Drop PD indicator  columns
dfnew_cleaned = df.drop(columns=["PD indicator"])

# Convert PD indicator to boolean data type
dfnew_cleaned["PD indicator"] = df["PD indicator"].astype(bool)

# Check for missing values
print(dfnew_cleaned.isnull().sum())

# Normalize the data
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
data_scaled = scaler.fit_transform(dfnew_cleaned[feature_columns])

# Convert scaled data into a DataFrame
data_scaled_df = pd.DataFrame(data_scaled, columns=feature_columns)

# Adding the PD indicator column
data_scaled_df["PD indicator"] = dfnew_cleaned["PD indicator"]

# Saving the cleaned and scaled data to a csv file
data_scaled_df.to_csv("cleaned_data.csv", index=False)

# reading the cleaned dataframe
cleaned_dataframe = pd.read_csv('/content/cleaned_scaled_data.csv')
cleaned_dataframe.head()

# dropping the PD indicator column to prep for machine lerning model
X = df.drop(columns=["PD indicator"])
y = df["PD indicator"]

# Spliting the data into train and set set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Tranforming the datframe
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Using SVM with Linear Kernel
svm_linear = SVC(kernel='linear')
svm_linear.fit(X_train_scaled, y_train)
y_pred_svm_linear = svm_linear.predict(X_test_scaled)

# Using SVM with Polynomial Kernel
svm_poly = SVC(kernel='poly', degree=3)
svm_poly.fit(X_train_scaled, y_train)
y_pred_svm_poly = svm_poly.predict(X_test_scaled)

# SVM with Radial Basis Function (RBF) Kernel
svm_rbf = SVC(kernel='rbf')
svm_rbf.fit(X_train_scaled, y_train)
y_pred_svm_rbf = svm_rbf.predict(X_test_scaled)

accuracy_svm = accuracy_score(y_test, y_pred_svm_linear)
accuracy_svmploy = accuracy_score(y_test, y_pred_svm_poly)
accuracy_svmrbf = accuracy_score(y_test, y_pred_svm_rbf)

print("SVM Accuracy:", accuracy_svm)
print("SVM Accuracy:", accuracy_svmploy)
print("SVM Accuracy:", accuracy_svmrbf)

print(classification_report(y_test, y_pred_svm_linear))
print(classification_report(y_test, y_pred_svm_poly))
print(classification_report(y_test, y_pred_svm_rbf))

conf_matrix_svm = confusion_matrix(y_test, y_pred_svm_linear)
print("\nSVM Confusion Matrix linear")
print(conf_matrix_svm)

conf_matrix_svm = confusion_matrix(y_test, y_pred_svm_poly)
print("\nSVM Confusion Matrix for poly")
print(conf_matrix_svm)

conf_matrix_svm = confusion_matrix(y_test, y_pred_svm_rbf)
print("\nSVM Confusion Matrix for rbf")
print(conf_matrix_svm)

# KNN with 5 neighbors
knn_5 = KNeighborsClassifier(n_neighbors=5)
knn_5.fit(X_train_scaled, y_train)
y_pred_knn_5 = knn_5.predict(X_test_scaled)

# KNN with 7 neighbors
knn_7 = KNeighborsClassifier(n_neighbors=7)
knn_7.fit(X_train_scaled, y_train)
y_pred_knn_7 = knn_7.predict(X_test_scaled)

accuracy_knn_5 = accuracy_score(y_test, y_pred_knn_5)
accuracy_knn_7 = accuracy_score(y_test, y_pred_knn_7)

print("KNN Accuracy:", accuracy_knn_5)
print("KNN Accuracy:", accuracy_knn_7)

print(classification_report(y_test, y_pred_knn_5))

print(classification_report(y_test, y_pred_knn_7))

# Confusion Matrix for KNN with 5 neighbour
conf_matrix_knn = confusion_matrix(y_test, y_pred_knn_5)
print("\nKNN Confusion Matrix for 5 neighbour")
print(conf_matrix_knn)

# Confusion Matrix for KNN with 7 neighbour
conf_matrix_knn = confusion_matrix(y_test, y_pred_knn_7)
print("\nKNN Confusion Matrix for 7 neighbour")
print(conf_matrix_knn)